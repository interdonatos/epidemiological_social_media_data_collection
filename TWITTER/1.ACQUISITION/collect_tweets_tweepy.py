# -*- coding: utf-8 -*-
"""collect_tweets_tweepy

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SyEnQc7txzm5akxKwmYKbRJCelV2IGJ4
"""

!pip install preprocessor

import tweepy
from tweepy import *
 
import pandas as pd
import csv
import re 
import string
import preprocessor as p
import json
 
access_token="XXX"
access_token_secret="XXX"
consumer_key="XXX"
consumer_secret="XXX"
 
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
 
api = tweepy.API(auth,wait_on_rate_limit=True)
 
csvFile = open('file-name_jsonformat_2411.txt', 'a')
csvWriter = csv.writer(csvFile)
#csvWriter.write('{"Tweets": [') #le rajouter manuellement après

search_words = "avian influenza"      # enter your words
new_search = search_words + " -filter:retweets"
#date_since="2021-11-05"
#date_until="2021-11-09"

for tweet in tweepy.Cursor(api.search,q=new_search,count=1000,
                           lang="en",
                           exclude_replies=True,
                           include_rts=False,
                           #since=date_since,
                           #until=date_until,
                           since_id=0, 
                           tweet_mode='extended' 
                           ).items(1000):
    #csvWriter.writerow([tweet.created_at, tweet.full_text.encode('utf-8'),tweet.user.screen_name.encode('utf-8'), tweet.user.location.encode('utf-8')])
    #csvWriter.writerow(['{"id": "',[tweet.id],'", "date": "',[tweet.created_at],'", "tweet": "',[tweet.full_text.encode('utf-8')],'" '' end_tweet'])
    csvWriter.writerow(['{id:'+str(tweet.id)+'date:'+str(tweet.created_at)+'tweet:'+str(tweet.full_text.encode('utf-8'))+'" end_tweet}'])
    #csvWriter.writerow([tweet.id, tweet.created_at, tweet.full_text.encode('utf-8'),' end_tweet'])
#csvWriter.writerow(']}') # #le rajouter manuellement après

import re
import json
#with open('/content/file-name_jsonformat_2411.txt') as json_data:
filename='/content/file-name_jsonformat_2411.txt'
file=open(filename,encoding="utf-8").read()
#file=json_data.read()

file=re.sub('"{','{',file)
file=re.sub('}"','}, ',file)
file=re.sub('"','',file)
file=re.sub('^','{"Tweets": [',file)
file=re.sub('{id:','{"id": "',file)
file=re.sub('date:','", "date": "',file)
file=re.sub('(tweet:b(\'"?"?|""?)|tweet:b)','", "tweet": "',file)
file=re.sub("' end_tweet",'", "end_tweet": "end_tweet"',file)
file=re.sub("end_tweet},",'", "end_tweet": "end_tweet"},',file)
file=re.sub('"end_tweet": "end_tweet" {', '"end_tweet": "end_tweet"',file)
#file=re.sub("\'","'",file)
file=re.sub('\'",','",',file)
file=re.sub('$',']}',file)
file=re.sub('"}, ]}\n]}','""}]}',file)
file=re.sub('""",','",',file)
file=re.sub('"",','"',file)
#file=re.sub("\\","",file)
file = file.replace("\\", "")
file=re.sub('""','"',file)
file=re.sub(r"\\n"," ",file) #suppression dex \n
file=re.sub(r"\\x[0-9a-z]+","",file) #suppression des caractères non unicode
#file= file.encode("ascii", "ignore") #suppression des caractères non ascii
open(filename,'w').write(file)

#out_file = open("/content/test1.json", "w", encoding="utf-8")
#json.dump(file, out_file, indent = 4, sort_keys = False)
#out_file.close()

#import json
#with open("/content/file-name_jsonformat_2411.txt", "r") as fin:
#  content = json.load(fin)
#with open("stringJson.txt", "w") as fout:
#  json.dump(content, fout, indent=1)
#json.dumps(file)
#with open('/content/file-name_jsonformat_2411.txt', 'w', encoding='utf-8') as f:
  #f.write(file)
print(type(file))